{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.Tensor([1]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([2]), requires_grad=True)\n",
    "b = Variable(torch.Tensor([3]), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print x.grad\n",
    "print w.grad\n",
    "print b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic autograd example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.randn(5, 3))\n",
    "y = Variable(torch.randn(5, 2))\n",
    "linear = nn.Linear(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: Parameter containing:\n",
      " 0.5579  0.0533  0.5382\n",
      " 0.5544  0.4830  0.2249\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "b: Parameter containing:\n",
      " 0.0390\n",
      " 0.1856\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'w:', linear.weight\n",
    "print 'b:', linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: Variable containing:\n",
      "-1.8514 -1.2267\n",
      "-0.1659  0.0622\n",
      "-0.4900 -0.3907\n",
      " 1.9085  0.5578\n",
      " 0.0063  0.0389\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
    "pred = linear(x)\n",
    "print 'pred:', pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: Variable containing:\n",
      " 2.0893\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(pred, y)\n",
    "print 'loss:', loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL/dw: Variable containing:\n",
      " 0.4403 -0.4173  2.3348\n",
      " 1.2912 -0.8032  1.1476\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "dL/db: Variable containing:\n",
      " 0.7460\n",
      "-0.1038\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print 'dL/dw:', linear.weight.grad\n",
    "print 'dL/db:', linear.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 step optimization: 1.99057543278\n"
     ]
    }
   ],
   "source": [
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print 'loss after 1 step optimization:', loss.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = torch.from_numpy(a)   #np -> torch\n",
    "c = b.numpy()             #torch -> np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n",
      "Extracting tar file\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dsets.CIFAR10(root='../data/',\n",
    "                              train=True,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print image.size()\n",
    "print label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomDataset():\n",
    "    def __init__(self):\n",
    "        # 1. Initialize file path or list of file names.\n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        return 0\n",
    "\n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=100,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth\" to /Users/zal/.torch/models/resnet18-5c106cde.pth\n",
      "100%|██████████| 46827520/46827520 [00:07<00:00, 9543694.27it/s]\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100])\n",
      "Variable containing:\n",
      "-0.0268  0.5486 -0.2649  ...  -0.7075  0.3512  0.2783\n",
      " 0.2035  0.9978 -0.3668  ...  -0.6232  0.2231  0.3093\n",
      " 0.1271  0.5256 -0.0925  ...   0.0782 -0.2478  0.4704\n",
      "          ...             ⋱             ...          \n",
      " 0.3371  0.8388 -0.4171  ...  -0.9723  0.3796  0.2666\n",
      " 0.3764  1.0292 -0.8678  ...  -0.0171 -0.2020  0.6846\n",
      "-0.4773  0.2810  0.3216  ...  -0.8836  0.7359  0.4897\n",
      "[torch.FloatTensor of size 10x100]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images = Variable(torch.randn(10, 3, 256, 256))\n",
    "outputs = resnet(images)\n",
    "print outputs.size()\n",
    "print outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0268\n",
      " 0.5486\n",
      "-0.2649\n",
      " 0.4104\n",
      " 0.5322\n",
      " 1.1841\n",
      "-0.5812\n",
      "-0.0493\n",
      " 0.0542\n",
      "-0.3008\n",
      "-0.4043\n",
      "-0.3789\n",
      " 1.0509\n",
      "-0.8859\n",
      "-0.5165\n",
      "-0.4250\n",
      "-1.3922\n",
      " 0.7892\n",
      "-1.0385\n",
      " 0.1172\n",
      "-1.2449\n",
      " 0.2854\n",
      " 0.1718\n",
      "-0.2114\n",
      "-0.1537\n",
      "-0.7267\n",
      " 0.0537\n",
      " 0.4967\n",
      "-0.6089\n",
      " 0.2851\n",
      "-0.3053\n",
      "-0.3085\n",
      " 1.1602\n",
      "-0.2257\n",
      " 0.4405\n",
      " 0.8428\n",
      "-1.1567\n",
      " 0.0100\n",
      " 0.8346\n",
      "-0.5473\n",
      "-0.2915\n",
      " 0.8987\n",
      " 0.1276\n",
      "-1.4882\n",
      "-0.4107\n",
      " 0.1422\n",
      "-0.3522\n",
      "-0.7499\n",
      " 0.5616\n",
      "-1.0327\n",
      " 0.1323\n",
      "-0.2244\n",
      "-0.2546\n",
      "-0.3500\n",
      "-0.4735\n",
      "-0.0302\n",
      "-0.1849\n",
      "-0.8251\n",
      " 0.5751\n",
      "-0.3224\n",
      "-1.4644\n",
      " 0.4885\n",
      "-0.2437\n",
      " 0.7424\n",
      "-0.3115\n",
      " 1.0801\n",
      " 0.0276\n",
      " 0.2142\n",
      "-0.1504\n",
      " 0.4341\n",
      " 1.3530\n",
      " 1.0293\n",
      " 0.0300\n",
      " 0.2730\n",
      " 0.8081\n",
      "-0.3452\n",
      " 0.2966\n",
      " 0.5419\n",
      "-1.0668\n",
      "-0.1672\n",
      "-0.1610\n",
      "-0.2529\n",
      " 0.4704\n",
      "-0.3122\n",
      "-0.6760\n",
      " 0.2370\n",
      " 0.0577\n",
      "-0.7685\n",
      " 0.6545\n",
      "-1.0316\n",
      "-0.1468\n",
      " 0.8644\n",
      "-0.0980\n",
      " 0.8381\n",
      "-0.6197\n",
      "-0.2307\n",
      " 0.4433\n",
      "-0.7075\n",
      " 0.3512\n",
      " 0.2783\n",
      "[torch.FloatTensor of size 100]\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(resnet, 'model.pkl')\n",
    "model = torch.load('model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'params.pkl')\n",
    "resnet.load_state_dict(torch.load('params.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
