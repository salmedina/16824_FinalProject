{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will prototype the data importer from the output of the CPM into the Pytorch format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import json\n",
    "import torch\n",
    "import glob\n",
    "from random import randint\n",
    "import os\n",
    "from os.path import join,basename\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.palplot(sns.color_palette(\"Set2\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/zal/CMU/Spring2017/16824/FinalProject/Data/mockup/'\n",
    "data_save_path = '/Users/zal/CMU/Spring2017/16824/FinalProject/Data/mockup.npz'\n",
    "\n",
    "action_labels_path = '/Users/zal/CMU/Spring2017/16824/FinalProject/Data/mockup_labels.txt'\n",
    "action_labels = []\n",
    "action_labels_idx = {}\n",
    "\n",
    "num_frames = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "        \n",
    "    return [x for x in os.listdir(path) if os.path.isdir(join(path,x)) and not x.startswith('.')]\n",
    "\n",
    "def get_list_inv_dict(in_list):\n",
    "    inv_dict = {}\n",
    "    for i,x in enumerate(in_list):\n",
    "        inv_dict[x] = i\n",
    "    return inv_dict\n",
    "\n",
    "def pose_data_to_numpy(video_pose_path):\n",
    "    frame_pose_paths = glob.glob(os.path.join(video_pose_path, '*.json'))\n",
    "    frame_feat_list = []\n",
    "    for fp_path in frame_pose_paths:\n",
    "        fp_data = json.load(open(fp_path))\n",
    "        frame_feat_list.append(fp_data['people']['body_parts'][0])\n",
    "    return numpy.array(frame_feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtain the classes and build structure\n",
    "2. Select the target classes\n",
    "3. Make the numpy structure\n",
    "4. Go through each of the classes\n",
    "    - Go through each of the videos in the class\n",
    "        - Go through each of the frames in the file\n",
    "            - Build the numpy array from the frame info\n",
    "            - Append to data samples struct\n",
    "5. Save on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_labels = get_dirs(data_path)\n",
    "action_labels_idx = get_list_inv_dict(action_labels)\n",
    "with open(action_labels_path, 'w') as alf:\n",
    "    alf.write('\\n'.join(action_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 human pose classes\n"
     ]
    }
   ],
   "source": [
    "sel_classes = ['BabyCrawling', 'BlowingCandles', 'BodyWeightSquats',\n",
    "               'HandstandPushups', 'HandstandWalking', 'PullUps', \n",
    "               'PushUps', 'RockClimbingIndoor', 'RopeClimbing',\n",
    "               'Swing', 'TaiChi', 'TrampolineJumping']\n",
    "print len(sel_classes),'human pose classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def which_dirs_in_path(path, dirs):\n",
    "    subdirs = os.listdir(path)\n",
    "    return [d for d in dirs if d in subdirs and os.path.isdir(join(path,d))]\n",
    "\n",
    "def extract_data(data_path, sel_classes, num_frames, actions_dict):\n",
    "    '''\n",
    "    Reads the data from the folders and loads into numpy\n",
    "    @returns: a tuple with the data samples and datalabels\n",
    "    '''\n",
    "    \n",
    "    #Verify that all sel_classes are in path and notify missing classes\n",
    "    found_classes = which_dirs_in_path(data_path, sel_classes)\n",
    "    if set(found_classes) != set(sel_classes):\n",
    "        print 'Not all the classes were found. The missing classes are:'\n",
    "        print ', '.join(list(set(sel_classes) - set(found_classes)))\n",
    "        \n",
    "    REQ_FRAMES = num_frames\n",
    "    data_samples = []\n",
    "    data_labels = []\n",
    "    # For each selected class\n",
    "    for sel_class in found_classes:\n",
    "        print 'Processing class {}'.format(sel_class) \n",
    "        # Get its full path and the videos which are dirs\n",
    "        sel_class_path = join(data_path, sel_class)\n",
    "        sel_class_videos = get_dirs(sel_class_path)\n",
    "        print 'Found {} videos for the class {}'.format(len(sel_class_videos), sel_class)\n",
    "\n",
    "        # For each video for the selected class\n",
    "        for video_name in sel_class_videos:\n",
    "            # Each of the json files correspond to each frame\n",
    "            vf_jsons = glob.glob(join(sel_class_path, video_name, '*.json'))\n",
    "            print 'Found {} frames for {}'.format(len(vf_jsons), video_name)\n",
    "\n",
    "            # Collect all the frames for  the video\n",
    "\n",
    "            last_pose = np.zeros(54) \n",
    "            video_poses = np.array([])\n",
    "            missing_count = 0\n",
    "            for vf_json_path in vf_jsons:\n",
    "                vf_json = json.load(open(vf_json_path))\n",
    "                if 'people' in vf_json and len(vf_json['people'])>0 and 'body_parts' in vf_json['people'][0]:\n",
    "                        frame_pose = vf_json['people'][0]['body_parts']\n",
    "                        if len(video_poses) < 1:\n",
    "                            video_poses = np.array([frame_pose], dtype=np.float32)\n",
    "                        else:\n",
    "                            video_poses = np.concatenate((video_poses, [frame_pose]))\n",
    "                        last_pose = frame_pose\n",
    "                else:\n",
    "                    if len(video_poses) < 1: #When the first frame did not find any pose\n",
    "                        continue\n",
    "                    missing_count += 1\n",
    "                    video_poses = np.concatenate((video_poses, [last_pose]))\n",
    "            if missing_count > 0:\n",
    "                print 'Missing frames: {}/{}'.format(missing_count, len(video_poses))\n",
    "            \n",
    "            if len(video_poses) < REQ_FRAMES:\n",
    "                # Loop through the video until we get the required length\n",
    "                loops = int(ceil(REQ_FRAMES/len(video_poses)))\n",
    "                video_poses = np.tile(video_poses, (loops, 1))[:REQ_FRAMES]\n",
    "            elif len(video_poses) > REQ_FRAMES:\n",
    "                # Select a segment at random from the video\n",
    "                start_idx = randint(0, len(video_poses)-REQ_FRAMES) # randint is inclusive\n",
    "                video_poses = video_poses[start_idx:start_idx+REQ_FRAMES]\n",
    "\n",
    "            # Append pose matrix to data tensor\n",
    "            if len(data_samples) < 1:\n",
    "                data_samples = np.array([video_poses], dtype=np.float32)\n",
    "            else:\n",
    "                data_samples = np.concatenate((data_samples, [video_poses]))\n",
    "\n",
    "            # Append label to label tensor\n",
    "            data_labels.append(actions_dict[sel_class])\n",
    "\n",
    "        assert len(data_samples) == len(data_labels)\n",
    "    \n",
    "    data_labels = np.array(data_labels)\n",
    "    \n",
    "    return data_samples, data_labels\n",
    "    \n",
    "def store_npdata(save_path, data, labels):\n",
    "    '''\n",
    "    Saves data into a compressed numpy binary file\n",
    "    @returns: None\n",
    "    '''\n",
    "    np.savez_compressed(save_path, data=data, labels=labels)\n",
    "    \n",
    "def load_npdata(save_path):\n",
    "    '''\n",
    "    Loades the stored binary data\n",
    "    @returns: tuple with data and labels as numpy arrays\n",
    "    '''\n",
    "    loaded_data = np.load(save_path)\n",
    "    data = loaded_data['data']\n",
    "    labels = loaded_data['labels']\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not all the classes were found. The missing classes are:\n",
      "TrampolineJumping, TaiChi, RopeClimbing, BabyCrawling, PushUps, RockClimbingIndoor, HandstandWalking, BlowingCandles, BodyWeightSquats, Swing, HandstandPushups\n",
      "Processing class PullUps\n",
      "Found 100 videos for the class PullUps\n",
      "Found 167 frames for v_PullUps_g01_c01\n",
      "Missing frames: 25/166\n",
      "Found 138 frames for v_PullUps_g01_c02\n",
      "Missing frames: 30/138\n",
      "Found 181 frames for v_PullUps_g01_c03\n",
      "Missing frames: 79/180\n",
      "Found 157 frames for v_PullUps_g01_c04\n",
      "Missing frames: 58/151\n",
      "Found 122 frames for v_PullUps_g02_c01\n",
      "Found 176 frames for v_PullUps_g02_c02\n",
      "Found 131 frames for v_PullUps_g02_c03\n",
      "Found 178 frames for v_PullUps_g02_c04\n",
      "Found 178 frames for v_PullUps_g03_c01\n",
      "Missing frames: 1/178\n",
      "Found 208 frames for v_PullUps_g03_c02\n",
      "Found 203 frames for v_PullUps_g03_c03\n",
      "Found 249 frames for v_PullUps_g03_c04\n",
      "Found 141 frames for v_PullUps_g04_c01\n",
      "Found 142 frames for v_PullUps_g04_c02\n",
      "Found 154 frames for v_PullUps_g04_c03\n",
      "Found 138 frames for v_PullUps_g04_c04\n",
      "Found 174 frames for v_PullUps_g05_c01\n",
      "Found 121 frames for v_PullUps_g05_c02\n",
      "Found 108 frames for v_PullUps_g05_c03\n",
      "Missing frames: 7/108\n",
      "Found 144 frames for v_PullUps_g05_c04\n",
      "Missing frames: 3/144\n",
      "Found 84 frames for v_PullUps_g06_c01\n",
      "Missing frames: 2/84\n",
      "Found 87 frames for v_PullUps_g06_c02\n",
      "Missing frames: 1/87\n",
      "Found 98 frames for v_PullUps_g06_c03\n",
      "Missing frames: 4/98\n",
      "Found 170 frames for v_PullUps_g06_c04\n",
      "Found 98 frames for v_PullUps_g07_c01\n",
      "Missing frames: 3/98\n",
      "Found 128 frames for v_PullUps_g07_c02\n",
      "Missing frames: 13/128\n",
      "Found 92 frames for v_PullUps_g07_c03\n",
      "Missing frames: 2/92\n",
      "Found 93 frames for v_PullUps_g07_c04\n",
      "Missing frames: 21/93\n",
      "Found 96 frames for v_PullUps_g08_c01\n",
      "Found 103 frames for v_PullUps_g08_c02\n",
      "Found 104 frames for v_PullUps_g08_c03\n",
      "Found 106 frames for v_PullUps_g08_c04\n",
      "Found 107 frames for v_PullUps_g09_c01\n",
      "Missing frames: 4/107\n",
      "Found 101 frames for v_PullUps_g09_c02\n",
      "Found 105 frames for v_PullUps_g09_c03\n",
      "Missing frames: 4/105\n",
      "Found 99 frames for v_PullUps_g09_c04\n",
      "Missing frames: 5/99\n",
      "Found 142 frames for v_PullUps_g10_c01\n",
      "Found 173 frames for v_PullUps_g10_c02\n",
      "Found 199 frames for v_PullUps_g10_c03\n",
      "Found 102 frames for v_PullUps_g10_c04\n",
      "Found 95 frames for v_PullUps_g11_c01\n",
      "Found 114 frames for v_PullUps_g11_c02\n",
      "Found 91 frames for v_PullUps_g11_c03\n",
      "Found 100 frames for v_PullUps_g11_c04\n",
      "Found 82 frames for v_PullUps_g12_c01\n",
      "Found 73 frames for v_PullUps_g12_c02\n",
      "Found 69 frames for v_PullUps_g12_c03\n",
      "Found 79 frames for v_PullUps_g12_c04\n",
      "Found 93 frames for v_PullUps_g13_c01\n",
      "Found 82 frames for v_PullUps_g13_c02\n",
      "Found 78 frames for v_PullUps_g13_c03\n",
      "Found 81 frames for v_PullUps_g13_c04\n",
      "Found 79 frames for v_PullUps_g14_c01\n",
      "Found 81 frames for v_PullUps_g14_c02\n",
      "Found 86 frames for v_PullUps_g14_c03\n",
      "Found 86 frames for v_PullUps_g14_c04\n",
      "Found 165 frames for v_PullUps_g15_c01\n",
      "Missing frames: 4/165\n",
      "Found 197 frames for v_PullUps_g15_c02\n",
      "Found 207 frames for v_PullUps_g15_c03\n",
      "Found 192 frames for v_PullUps_g15_c04\n",
      "Found 132 frames for v_PullUps_g16_c01\n",
      "Found 134 frames for v_PullUps_g16_c02\n",
      "Found 141 frames for v_PullUps_g16_c03\n",
      "Found 144 frames for v_PullUps_g16_c04\n",
      "Found 164 frames for v_PullUps_g17_c01\n",
      "Found 186 frames for v_PullUps_g17_c02\n",
      "Found 202 frames for v_PullUps_g17_c03\n",
      "Found 226 frames for v_PullUps_g17_c04\n",
      "Found 155 frames for v_PullUps_g18_c01\n",
      "Found 164 frames for v_PullUps_g18_c02\n",
      "Found 161 frames for v_PullUps_g18_c03\n",
      "Found 163 frames for v_PullUps_g18_c04\n",
      "Found 111 frames for v_PullUps_g19_c01\n",
      "Found 102 frames for v_PullUps_g19_c02\n",
      "Found 108 frames for v_PullUps_g19_c03\n",
      "Found 104 frames for v_PullUps_g19_c04\n",
      "Found 152 frames for v_PullUps_g20_c01\n",
      "Found 217 frames for v_PullUps_g20_c02\n",
      "Found 197 frames for v_PullUps_g20_c03\n",
      "Found 188 frames for v_PullUps_g20_c04\n",
      "Found 165 frames for v_PullUps_g21_c01\n",
      "Missing frames: 82/165\n",
      "Found 177 frames for v_PullUps_g21_c02\n",
      "Missing frames: 107/176\n",
      "Found 183 frames for v_PullUps_g21_c03\n",
      "Missing frames: 99/182\n",
      "Found 193 frames for v_PullUps_g21_c04\n",
      "Missing frames: 68/193\n",
      "Found 106 frames for v_PullUps_g22_c01\n",
      "Found 105 frames for v_PullUps_g22_c02\n",
      "Found 106 frames for v_PullUps_g22_c03\n",
      "Found 144 frames for v_PullUps_g22_c04\n",
      "Found 178 frames for v_PullUps_g23_c01\n",
      "Found 189 frames for v_PullUps_g23_c02\n",
      "Found 187 frames for v_PullUps_g23_c03\n",
      "Found 194 frames for v_PullUps_g23_c04\n",
      "Found 154 frames for v_PullUps_g24_c01\n",
      "Found 192 frames for v_PullUps_g24_c02\n",
      "Found 181 frames for v_PullUps_g24_c03\n",
      "Found 198 frames for v_PullUps_g24_c04\n",
      "Found 92 frames for v_PullUps_g25_c01\n",
      "Missing frames: 28/80\n",
      "Found 110 frames for v_PullUps_g25_c02\n",
      "Found 67 frames for v_PullUps_g25_c03\n",
      "Missing frames: 4/67\n",
      "Found 79 frames for v_PullUps_g25_c04\n",
      "Missing frames: 47/68\n"
     ]
    }
   ],
   "source": [
    "data, labels = extract_data(data_path, sel_classes, 180, action_labels_idx)\n",
    "store_npdata(data_save_path, data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class BabyCrawling\n",
      "Found 0 videos for the class BabyCrawling\n",
      "Processing class BlowingCandles\n",
      "Found 0 videos for the class BlowingCandles\n",
      "Processing class BodyWeightSquats\n",
      "Found 0 videos for the class BodyWeightSquats\n",
      "Processing class HandstandPushups\n",
      "Found 0 videos for the class HandstandPushups\n",
      "Processing class HandstandWalking\n",
      "Found 0 videos for the class HandstandWalking\n",
      "Processing class PullUps\n",
      "Found 100 videos for the class PullUps\n",
      "Found 167 frames for v_PullUps_g01_c01\n",
      "appended first elem\n",
      "165\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended first element to data_samples\n",
      "Found 138 frames for v_PullUps_g01_c02\n",
      "appended first elem\n",
      "137\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 181 frames for v_PullUps_g01_c03\n",
      "appended first elem\n",
      "179\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 157 frames for v_PullUps_g01_c04\n",
      "appended first elem\n",
      "150\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 122 frames for v_PullUps_g02_c01\n",
      "appended first elem\n",
      "121\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 176 frames for v_PullUps_g02_c02\n",
      "appended first elem\n",
      "175\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 131 frames for v_PullUps_g02_c03\n",
      "appended first elem\n",
      "130\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 178 frames for v_PullUps_g02_c04\n",
      "appended first elem\n",
      "177\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 178 frames for v_PullUps_g03_c01\n",
      "appended first elem\n",
      "177\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 208 frames for v_PullUps_g03_c02\n",
      "appended first elem\n",
      "207\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 203 frames for v_PullUps_g03_c03\n",
      "appended first elem\n",
      "202\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 249 frames for v_PullUps_g03_c04\n",
      "appended first elem\n",
      "248\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 141 frames for v_PullUps_g04_c01\n",
      "appended first elem\n",
      "140\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 142 frames for v_PullUps_g04_c02\n",
      "appended first elem\n",
      "141\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 154 frames for v_PullUps_g04_c03\n",
      "appended first elem\n",
      "153\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 138 frames for v_PullUps_g04_c04\n",
      "appended first elem\n",
      "137\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 174 frames for v_PullUps_g05_c01\n",
      "appended first elem\n",
      "173\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 121 frames for v_PullUps_g05_c02\n",
      "appended first elem\n",
      "120\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 108 frames for v_PullUps_g05_c03\n",
      "appended first elem\n",
      "107\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 144 frames for v_PullUps_g05_c04\n",
      "appended first elem\n",
      "143\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 84 frames for v_PullUps_g06_c01\n",
      "appended first elem\n",
      "83\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 87 frames for v_PullUps_g06_c02\n",
      "appended first elem\n",
      "86\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 98 frames for v_PullUps_g06_c03\n",
      "appended first elem\n",
      "97\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 170 frames for v_PullUps_g06_c04\n",
      "appended first elem\n",
      "169\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 98 frames for v_PullUps_g07_c01\n",
      "appended first elem\n",
      "97\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 128 frames for v_PullUps_g07_c02\n",
      "appended first elem\n",
      "127\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 92 frames for v_PullUps_g07_c03\n",
      "appended first elem\n",
      "91\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 93 frames for v_PullUps_g07_c04\n",
      "appended first elem\n",
      "92\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 96 frames for v_PullUps_g08_c01\n",
      "appended first elem\n",
      "95\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 103 frames for v_PullUps_g08_c02\n",
      "appended first elem\n",
      "102\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 104 frames for v_PullUps_g08_c03\n",
      "appended first elem\n",
      "103\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 106 frames for v_PullUps_g08_c04\n",
      "appended first elem\n",
      "105\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 107 frames for v_PullUps_g09_c01\n",
      "appended first elem\n",
      "106\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 101 frames for v_PullUps_g09_c02\n",
      "appended first elem\n",
      "100\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 105 frames for v_PullUps_g09_c03\n",
      "appended first elem\n",
      "104\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 99 frames for v_PullUps_g09_c04\n",
      "appended first elem\n",
      "98\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 142 frames for v_PullUps_g10_c01\n",
      "appended first elem\n",
      "141\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 173 frames for v_PullUps_g10_c02\n",
      "appended first elem\n",
      "172\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 199 frames for v_PullUps_g10_c03\n",
      "appended first elem\n",
      "198\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 102 frames for v_PullUps_g10_c04\n",
      "appended first elem\n",
      "101\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 95 frames for v_PullUps_g11_c01\n",
      "appended first elem\n",
      "94\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 114 frames for v_PullUps_g11_c02\n",
      "appended first elem\n",
      "113\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 91 frames for v_PullUps_g11_c03\n",
      "appended first elem\n",
      "90\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 100 frames for v_PullUps_g11_c04\n",
      "appended first elem\n",
      "99\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 82 frames for v_PullUps_g12_c01\n",
      "appended first elem\n",
      "81\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 73 frames for v_PullUps_g12_c02\n",
      "appended first elem\n",
      "72\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 69 frames for v_PullUps_g12_c03\n",
      "appended first elem\n",
      "68\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 79 frames for v_PullUps_g12_c04\n",
      "appended first elem\n",
      "78\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 93 frames for v_PullUps_g13_c01\n",
      "appended first elem\n",
      "92\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 82 frames for v_PullUps_g13_c02\n",
      "appended first elem\n",
      "81\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 78 frames for v_PullUps_g13_c03\n",
      "appended first elem\n",
      "77\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 81 frames for v_PullUps_g13_c04\n",
      "appended first elem\n",
      "80\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 79 frames for v_PullUps_g14_c01\n",
      "appended first elem\n",
      "78\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 81 frames for v_PullUps_g14_c02\n",
      "appended first elem\n",
      "80\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 86 frames for v_PullUps_g14_c03\n",
      "appended first elem\n",
      "85\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 86 frames for v_PullUps_g14_c04\n",
      "appended first elem\n",
      "85\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 165 frames for v_PullUps_g15_c01\n",
      "appended first elem\n",
      "164\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 197 frames for v_PullUps_g15_c02\n",
      "appended first elem\n",
      "196\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 207 frames for v_PullUps_g15_c03\n",
      "appended first elem\n",
      "206\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 192 frames for v_PullUps_g15_c04\n",
      "appended first elem\n",
      "191\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 132 frames for v_PullUps_g16_c01\n",
      "appended first elem\n",
      "131\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 134 frames for v_PullUps_g16_c02\n",
      "appended first elem\n",
      "133\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 141 frames for v_PullUps_g16_c03\n",
      "appended first elem\n",
      "140\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 144 frames for v_PullUps_g16_c04\n",
      "appended first elem\n",
      "143\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 164 frames for v_PullUps_g17_c01\n",
      "appended first elem\n",
      "163\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 186 frames for v_PullUps_g17_c02\n",
      "appended first elem\n",
      "185\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 202 frames for v_PullUps_g17_c03\n",
      "appended first elem\n",
      "201\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 226 frames for v_PullUps_g17_c04\n",
      "appended first elem\n",
      "225\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 155 frames for v_PullUps_g18_c01\n",
      "appended first elem\n",
      "154\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 164 frames for v_PullUps_g18_c02\n",
      "appended first elem\n",
      "163\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 161 frames for v_PullUps_g18_c03\n",
      "appended first elem\n",
      "160\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 163 frames for v_PullUps_g18_c04\n",
      "appended first elem\n",
      "162\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 111 frames for v_PullUps_g19_c01\n",
      "appended first elem\n",
      "110\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 102 frames for v_PullUps_g19_c02\n",
      "appended first elem\n",
      "101\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 108 frames for v_PullUps_g19_c03\n",
      "appended first elem\n",
      "107\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 104 frames for v_PullUps_g19_c04\n",
      "appended first elem\n",
      "103\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 152 frames for v_PullUps_g20_c01\n",
      "appended first elem\n",
      "151\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 217 frames for v_PullUps_g20_c02\n",
      "appended first elem\n",
      "216\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 197 frames for v_PullUps_g20_c03\n",
      "appended first elem\n",
      "196\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 188 frames for v_PullUps_g20_c04\n",
      "appended first elem\n",
      "187\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 165 frames for v_PullUps_g21_c01\n",
      "appended first elem\n",
      "164\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 177 frames for v_PullUps_g21_c02\n",
      "appended first elem\n",
      "175\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 183 frames for v_PullUps_g21_c03\n",
      "appended first elem\n",
      "181\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 193 frames for v_PullUps_g21_c04\n",
      "appended first elem\n",
      "192\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 106 frames for v_PullUps_g22_c01\n",
      "appended first elem\n",
      "105\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 105 frames for v_PullUps_g22_c02\n",
      "appended first elem\n",
      "104\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 106 frames for v_PullUps_g22_c03\n",
      "appended first elem\n",
      "105\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 144 frames for v_PullUps_g22_c04\n",
      "appended first elem\n",
      "143\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 178 frames for v_PullUps_g23_c01\n",
      "appended first elem\n",
      "177\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 189 frames for v_PullUps_g23_c02\n",
      "appended first elem\n",
      "188\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 187 frames for v_PullUps_g23_c03\n",
      "appended first elem\n",
      "186\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 194 frames for v_PullUps_g23_c04\n",
      "appended first elem\n",
      "193\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 154 frames for v_PullUps_g24_c01\n",
      "appended first elem\n",
      "153\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 192 frames for v_PullUps_g24_c02\n",
      "appended first elem\n",
      "191\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 181 frames for v_PullUps_g24_c03\n",
      "appended first elem\n",
      "180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 198 frames for v_PullUps_g24_c04\n",
      "appended first elem\n",
      "197\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 92 frames for v_PullUps_g25_c01\n",
      "appended first elem\n",
      "79\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 110 frames for v_PullUps_g25_c02\n",
      "appended first elem\n",
      "109\n",
      "Loops 2\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 67 frames for v_PullUps_g25_c03\n",
      "appended first elem\n",
      "66\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Found 79 frames for v_PullUps_g25_c04\n",
      "appended first elem\n",
      "67\n",
      "Loops 3\n",
      "Video poses len: 180\n",
      "Video poses shape: (180, 54)\n",
      "appended element to data samples (180, 54)\n",
      "Processing class PushUps\n",
      "Found 0 videos for the class PushUps\n",
      "Processing class RockClimbingIndoor\n",
      "Found 0 videos for the class RockClimbingIndoor\n",
      "Processing class RopeClimbing\n",
      "Found 0 videos for the class RopeClimbing\n",
      "Processing class Swing\n",
      "Found 0 videos for the class Swing\n",
      "Processing class TaiChi\n",
      "Found 0 videos for the class TaiChi\n",
      "Processing class TrampolineJumping\n",
      "Found 0 videos for the class TrampolineJumping\n",
      "Data tensor ndim: 3, nsamples: 100, shape: (100, 180, 54)\n",
      "Labels tensor ndim: 1, nsamples: 100\n",
      "<type 'numpy.ndarray'> 3 (100, 180, 54)\n",
      "<type 'numpy.ndarray'> 3 (100, 180, 54)\n"
     ]
    }
   ],
   "source": [
    "REQ_FRAMES = 180\n",
    "data_samples = []\n",
    "data_labels = []\n",
    "# For each selected class\n",
    "for sel_class in sel_classes:\n",
    "    print 'Processing class {}'.format(sel_class) \n",
    "    # Get its full path and the videos which are dirs\n",
    "    sel_class_path = join(data_path, sel_class)\n",
    "    sel_class_videos = get_dirs(sel_class_path)\n",
    "    print 'Found {} videos for the class {}'.format(len(sel_class_videos), sel_class)\n",
    "    \n",
    "    # For each video for the selected class\n",
    "    for video_name in sel_class_videos:\n",
    "        # Each of the json files correspond to each frame\n",
    "        vf_jsons = glob.glob(join(sel_class_path, video_name, '*.json'))\n",
    "        print 'Found {} frames for {}'.format(len(vf_jsons), video_name)\n",
    "        \n",
    "        # Collect all the frames for  the video\n",
    "        \n",
    "        last_pose = np.zeros(54) \n",
    "        video_poses = np.array([])\n",
    "        for vf_json_path in vf_jsons:\n",
    "            vf_json = json.load(open(vf_json_path))\n",
    "            if 'people' in vf_json and len(vf_json['people'])>0 and 'body_parts' in vf_json['people'][0]:\n",
    "                    frame_pose = vf_json['people'][0]['body_parts']\n",
    "                    if len(video_poses) < 1:\n",
    "                        print 'appended first elem'\n",
    "                        video_poses = np.array([frame_pose], dtype=np.float32)\n",
    "                    else:\n",
    "                        video_poses = np.concatenate((video_poses, [frame_pose]))\n",
    "                    last_pose = frame_pose\n",
    "            else:\n",
    "                if len(video_poses) < 1:\n",
    "                    continue\n",
    "                video_poses = np.concatenate((video_poses, [last_pose]))\n",
    "        \n",
    "        video_poses = video_poses[1:]\n",
    "        print len(video_poses)\n",
    "        if len(video_poses) < REQ_FRAMES:\n",
    "            # Loop through the video until we get the required length\n",
    "            loops = int(ceil(REQ_FRAMES/len(video_poses)))\n",
    "            video_poses = np.tile(video_poses, (loops, 1))[:REQ_FRAMES]\n",
    "            print 'Loops',loops\n",
    "            print 'Video poses len:', len(video_poses)\n",
    "        elif len(video_poses) > REQ_FRAMES:\n",
    "            # Select a segment at random from the video\n",
    "            start_idx = randint(0, len(video_poses)-REQ_FRAMES) # randint is inclusive\n",
    "            video_poses = video_poses[start_idx:start_idx+REQ_FRAMES]\n",
    "        print 'Video poses shape:', video_poses.shape\n",
    "        \n",
    "        # Append pose matrix to data tensor\n",
    "        if len(data_samples) < 1:\n",
    "            print 'appended first element to data_samples'\n",
    "            data_samples = np.array([video_poses], dtype=np.float32)\n",
    "        else:\n",
    "            print 'appended element to data samples', video_poses.shape\n",
    "            data_samples = np.concatenate((data_samples, [video_poses]))\n",
    "\n",
    "        # Append label to label tensor\n",
    "        data_labels.append(action_labels_idx[sel_class])\n",
    "        \n",
    "    assert len(data_samples) == len(data_labels)\n",
    "\n",
    "data_labels = np.array(data_labels)\n",
    "print 'Data tensor ndim: {}, nsamples: {}, shape: {}'.format(data_samples.ndim, len(data_samples), data_samples.shape)\n",
    "print 'Labels tensor ndim: {}, nsamples: {}'.format(data_labels.ndim, len(data_labels))\n",
    "print type(data_samples), data_samples.ndim, data_samples.shape\n",
    "np.savez_compressed(data_save_path, data=data_samples, labels=data_labels)\n",
    "print type(data_samples), data_samples.ndim, data_samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import into Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_load = np.load(data_save_path)\n",
    "data = data_load['data']\n",
    "labels = data_load['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> 3 (100, 180, 54)\n",
      "<type 'numpy.ndarray'> 3 (100, 180, 54)\n",
      "<type 'numpy.ndarray'> 1 (100,)\n"
     ]
    }
   ],
   "source": [
    "print type(data_samples), data_samples.ndim, data_samples.shape\n",
    "print type(data), data.ndim, data.shape\n",
    "print type(labels), labels.ndim, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'>\n",
      "torch.Size([100, 180, 54])\n"
     ]
    }
   ],
   "source": [
    "data_tensor = torch.from_numpy(data)\n",
    "data_tensor = data_tensor.float()\n",
    "print type(data_tensor)\n",
    "print data_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistics from selected classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First get the number of videos per class\n",
    "def get_numvideos_for_classes(data_path, classes):\n",
    "    num_videos = []\n",
    "    for sel_class in classes:\n",
    "        sel_class_path = join(data_path, sel_class)\n",
    "        sel_class_videos = get_dirs(sel_class_path)\n",
    "        print '{},{}'.format(len(sel_class_videos), sel_class)\n",
    "        num_videos.append(len(sel_class_videos))\n",
    "    return num_videos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
